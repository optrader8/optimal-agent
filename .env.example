# Model Provider: 'ollama' or 'openai'
USE_OPENAI=true

# For Ollama (when USE_OPENAI=false)
MODEL_NAME=qwen:7b
MODEL_ENDPOINT=http://localhost:11434

# For OpenAI-compatible API (when USE_OPENAI=true)
OPENAI_BASE_URL=your-server-url-here
OPENAI_API_KEY=your-api-key-here
# Model name (e.g., openai/gpt-4o, gpt-3.5-turbo, etc.)
MODEL_NAME=openai/gpt-4o

# General settings
CONTEXT_WINDOW=4096
MAX_TOKENS=2048
TEMPERATURE=0.7
